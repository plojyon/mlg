{"cells":[{"cell_type":"markdown","metadata":{"id":"ecD7YB79oDnP"},"source":["In this project, we will train a GNN to perform link prediction on a heterogenous graph from the Spotify Million Playlists dataset."]},{"cell_type":"markdown","metadata":{"id":"EA5fr8_soDpI"},"source":["# Import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F97y-Wm0oDpJ"},"outputs":[],"source":["import tqdm\n","import torch\n","import torch_geometric\n","import numpy as np\n","import time\n","import matplotlib.pyplot as plt\n","import torch_geometric.transforms as T\n","from torcheval.metrics import BinaryAccuracy\n","\n","import itertools\n","import time\n","import networkx as nx\n","import json\n","import os\n","\n","import networkx as nx\n","from tqdm import tqdm\n"]},{"cell_type":"markdown","metadata":{"id":"qDePP3tDoDpN"},"source":["# Configuration"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"dL4MoHTeoDpO"},"source":["Dataset files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g4a4D5lYoDpP"},"outputs":[],"source":["base = \"spotify_million_playlist_dataset\"\n","dataset_path = base + \"/data\""]},{"cell_type":"markdown","metadata":{"id":"HNaM4ayeoDpS"},"source":["# Load graph"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VmjhWT20oDpT"},"outputs":[],"source":["\n","def load_graph(dataset_path=dataset_path):\n","    \"\"\"Load a nx.Graph from disk.\"\"\"\n","    filenames = os.listdir(dataset_path)\n","    G = nx.DiGraph()\n","    for i in tqdm(range(len(filenames)), unit=\"files\"):\n","        with open(os.path.join(dataset_path, filenames[i])) as json_file:\n","            playlists = json.load(json_file)[\"playlists\"]\n","            for playlist in playlists:\n","                playlist_name = f\"spotify:playlist:{playlist['pid']}\"\n","                G.add_node(playlist_name, node_type=\"playlist\", num_followers=playlist[\"num_followers\"], num_tracks=playlist[\"num_tracks\"], num_artists=playlist[\"num_artists\"], num_albums=playlist[\"num_albums\"], duration_ms=playlist[\"duration_ms\"], collaborative=playlist[\"collaborative\"], num_edits=playlist[\"num_edits\"])\n","                for track in playlist[\"tracks\"]:\n","                    G.add_node(track[\"track_uri\"], node_type=\"track\", duration=track[\"duration_ms\"])\n","                    G.add_node(track[\"album_uri\"], node_type=\"album\")\n","                    G.add_node(track[\"artist_uri\"], node_type=\"artist\")\n","\n","                    G.add_edge(track[\"track_uri\"], playlist_name, edge_type=\"track-playlist\")\n","                    G.add_edge(track[\"track_uri\"], track[\"album_uri\"], edge_type=\"track-album\")\n","                    G.add_edge(track[\"track_uri\"], track[\"artist_uri\"], edge_type=\"track-artist\")\n","    return G\n","\n","def nx2hetero(G):\n","    \"\"\"Convert a nx.Graph into a torch_geometric.data.HeteroData object.\"\"\"\n","    ids_by_type = {\n","        \"playlist\": {},\n","        \"track\": {},\n","        \"artist\": {},\n","        \"album\": {}\n","    }\n","\n","    def node_id(node_type, id):\n","        d = ids_by_type[node_type]\n","        if id not in d:\n","            d[id] = len(d)\n","        return d[id]\n","\n","    node_features_by_type = {\n","        \"playlist\": [],\n","        \"track\": [],\n","        \"artist\": [],\n","        \"album\": []\n","    }\n","\n","    # comment:\n","    # {\n","    #     \"name\": \"musical\",\n","    #     \"collaborative\": \"false\",\n","    #     \"pid\": 5,\n","    #     \"modified_at\": 1493424000,\n","    #     \"num_albums\": 7,\n","    #     \"num_tracks\": 12,\n","    #     \"num_followers\": 1,\n","    #     \"num_edits\": 2,\n","    #     \"duration_ms\": 2657366,\n","    #     \"num_artists\": 6,\n","    #     \"tracks\": [\n","    #         {\n","    #             \"pos\": 0,\n","    #             \"artist_name\": \"Degiheugi\",\n","    #             \"track_uri\": \"spotify:track:7vqa3sDmtEaVJ2gcvxtRID\",\n","    #             \"artist_uri\": \"spotify:artist:3V2paBXEoZIAhfZRJmo2jL\",\n","    #             \"track_name\": \"Finalement\",\n","    #             \"album_uri\": \"spotify:album:2KrRMJ9z7Xjoz1Az4O6UML\",\n","    #             \"duration_ms\": 166264,\n","    #             \"album_name\": \"Dancing Chords and Fireflies\"\n","    #         },\n","    #     ],\n","\n","    # })\n","\n","    for node in G.nodes(data=True):\n","        t = node[1][\"node_type\"]\n","        node_id(t, node[0])\n","        if t == \"playlist\":\n","            if node[1][\"collaborative\"] not in (\"true\", \"false\"):\n","                raise ValueError(f\"collaborative is not a boolean: {node[1]['collaborative']}\")\n","            node_features_by_type[\"playlist\"] += [[node[1][\"num_followers\"], node[1][\"collaborative\"] == 'true', node[1][\"num_albums\"], node[1][\"num_tracks\"], node[1][\"num_edits\"], node[1][\"duration_ms\"], node[1][\"num_artists\"]]]\n","        elif t == \"track\":\n","            distances = nx.single_source_shortest_path_length(G, node[0], cutoff=2)\n","            node_features_by_type[\"track\"] += [[node[1][\"duration\"], len(distances)]]\n","        elif t == \"artist\":\n","            distances = nx.single_source_shortest_path_length(G, node[0], cutoff=2)\n","            node_features_by_type[\"artist\"] += [[len(distances)]]\n","        elif t == \"album\":\n","            distances = nx.single_source_shortest_path_length(G, node[0], cutoff=2)\n","            node_features_by_type[\"album\"] += [[len(distances)]]\n","\n","    edge_index_by_type = {\n","        (\"track\", \"contains\", \"playlist\"): [],\n","        (\"track\", \"includes\", \"album\"): [],\n","        (\"track\", \"authors\", \"artist\"): []\n","    }\n","    existing_edges = set()\n","    for edge in G.edges(data=True):\n","        track_node = edge[0]\n","        other_node = edge[1]\n","        if \"track\" not in track_node:\n","            track_node, other_node = other_node, track_node\n","\n","        if (track_node, other_node) in existing_edges:\n","            continue\n","\n","        if G[edge[0]][edge[1]][\"edge_type\"] == \"track-playlist\":\n","            s_id = node_id(\"track\", track_node)\n","            d_id = node_id(\"playlist\", other_node)\n","\n","            edge_index_by_type[(\"track\", \"contains\", \"playlist\")] += [(s_id, d_id)]\n","            \n","        elif G[edge[0]][edge[1]][\"edge_type\"] == \"track-album\":\n","            s_id = node_id(\"track\", track_node)\n","            d_id = node_id(\"album\", other_node)\n","\n","            edge_index_by_type[(\"track\", \"includes\", \"album\")] += [(s_id, d_id)]\n","\n","        elif G[edge[0]][edge[1]][\"edge_type\"] == \"track-artist\":\n","            s_id = node_id(\"track\", track_node)\n","            d_id = node_id(\"artist\", other_node)\n","\n","            edge_index_by_type[(\"track\", \"authors\", \"artist\")] += [(s_id, d_id)]\n","\n","        existing_edges.add((track_node, other_node))\n","\n","    # construct HeteroData\n","    hetero = torch_geometric.data.HeteroData()\n","\n","    # add initial node features\n","    hetero[\"playlist\"].x = torch.FloatTensor(node_features_by_type[\"playlist\"]).reshape(-1,len(node_features_by_type[\"playlist\"][0]))\n","    hetero[\"track\"].x = torch.FloatTensor(node_features_by_type[\"track\"]).reshape(-1,len(node_features_by_type[\"track\"][0]))\n","    hetero[\"artist\"].x = torch.FloatTensor(node_features_by_type[\"artist\"]).reshape(-1,len(node_features_by_type[\"artist\"][0]))\n","    hetero[\"album\"].x = torch.FloatTensor(node_features_by_type[\"album\"]).reshape(-1,len(node_features_by_type[\"album\"][0]))\n","\n","    # add edge indices\n","    hetero[\"track\", \"contains\", \"playlist\"].edge_index = torch.tensor(edge_index_by_type[(\"track\", \"contains\", \"playlist\")]).t()\n","    hetero[\"track\", \"includes\", \"album\"].edge_index = torch.tensor(edge_index_by_type[(\"track\", \"includes\", \"album\")]).t()\n","    hetero[\"track\", \"authors\", \"artist\"].edge_index = torch.tensor(edge_index_by_type[(\"track\", \"authors\", \"artist\")]).t()\n","\n","    # post-processing\n","    hetero = torch_geometric.transforms.ToUndirected()(hetero)\n","    hetero = torch_geometric.transforms.NormalizeFeatures()(hetero)\n","    return hetero\n","\n","def ghetero2datasets(ghetero):\n","    \"\"\"Split the dataset into train, validation and test sets.\"\"\"\n","    transform = T.Compose([\n","        T.NormalizeFeatures(),\n","        T.RandomLinkSplit(\n","            num_val=0.1,\n","            num_test=0.1,\n","            disjoint_train_ratio=0.3,\n","            neg_sampling_ratio=2.0,\n","            add_negative_train_samples=False,\n","            edge_types=(\"track\", \"contains\", \"playlist\"),\n","            rev_edge_types=(\"playlist\", \"rev_contains\", \"track\"),\n","        )\n","    ])\n","\n","    return transform(ghetero)  # 3-tuple: data_train, data_val, data_test"]},{"cell_type":"markdown","metadata":{"id":"kjLRphIBoDpZ"},"source":["# Preprocessing"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We took a subset of our dataset by taking a subgraph of 5000 nodes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gFIbjReioDpa"},"outputs":[],"source":["def get_neigh_of_edge_type(G, edge_type, node):\n","    undirected_neigh = itertools.chain(G.neighbors(node), G.predecessors(node))\n","    return [n for n in undirected_neigh if G.succ[node].get(n, dict()).get('edge_type', None) == edge_type or G.pred[node].get(n, dict()).get('edge_type', None) == edge_type]\n","\n","def top_n_by_followers(G, n, node_type):\n","    \"\"\"Get all nodes of type `node_type`.\"\"\"\n","    playlists = [node for node in G.nodes(data=True) if node[1][\"node_type\"] == node_type]\n","    return sorted(playlists, key=lambda x:\"num_followers\" in x[1] and x[1][\"num_followers\"], reverse=True)[:n]\n","\n","def get_smart_playlist_subset(G, playlists_to_keep):\n","    keep_nodes = set()\n","    for node in playlists_to_keep:\n","        keep_nodes.add(node[0])\n","        tracks = get_neigh_of_edge_type(G, \"track-playlist\", node[0])\n","        artists_and_albums = []\n","\n","        for track in tracks:\n","            artists_and_albums += get_neigh_of_edge_type(G, \"track-artist\", track)\n","            artists_and_albums += get_neigh_of_edge_type(G, \"track-album\", track)\n","        \n","        keep_nodes = keep_nodes.union(set(tracks))\n","        keep_nodes = keep_nodes.union(set(artists_and_albums))\n","    return keep_nodes\n","\n","def smart_split(G, splits=[100,500,1000,5000,10000]):\n","    ret = [None for _ in splits]\n","    for i in tqdm(splits):\n","        print(f\"[{i}] started\")\n","        start = time.time()\n","        playlists_to_keep = top_n_by_followers(G, i, \"playlist\")\n","        print(f\"[{i}] got top n playlists in {time.time() - start} seconds\")\n","        start = time.time()\n","        keep_nodes = get_smart_playlist_subset(G, playlists_to_keep)\n","        print(f\"[{i}] finshed getting neighbors in {time.time() - start} seconds\")\n","        print(f\"\\t({len(keep_nodes)} nodes = {len(keep_nodes)/len(G.nodes)} % of graph)\")\n","        start = time.time()\n","        G_sub = nx.Graph(G.subgraph(keep_nodes))\n","        print(f\"[{i}] finished subgraphing in {time.time() - start} seconds\")\n","        start = time.time()\n","        splits[i] = G_sub\n","        print(f\"[{i}] finished pickling in {time.time() - start} seconds\")\n","    return ret"]},{"cell_type":"markdown","metadata":{"id":"W9OptJoLoDpc"},"source":["# Model"]},{"cell_type":"markdown","metadata":{"id":"PlxTcl7noDpc"},"source":["Check if cuda is available"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wjSQM5V_oDp4"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{"id":"aFetupGuoDp5"},"source":["GNN embedding prediction network (three SAGEConv layers)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YF2ffwokoDp6"},"outputs":[],"source":["class GNN(torch.nn.Module):\n","    def __init__(self, hidden_channels):\n","        super().__init__()\n","        self.conv1 = torch_geometric.nn.SAGEConv((-1, -1), hidden_channels, normalize=True, dropout=True, bias=True, dropout_prob=0.1)\n","        self.conv2 = torch_geometric.nn.SAGEConv((-1, -1), hidden_channels, normalize=True, dropout=True, bias=True, dropout_prob=0.1)\n","        self.conv3 = torch_geometric.nn.SAGEConv((-1, -1), hidden_channels)\n","\n","        self.reset_parameters()\n","\n","    def forward(self, x, edge_index):\n","        x = self.conv1(x, edge_index)\n","        x = torch.nn.functional.leaky_relu(x, negative_slope=0.1)\n","        x = self.conv2(x, edge_index)\n","        x = torch.nn.functional.leaky_relu(x, negative_slope=0.1)\n","        x = self.conv3(x, edge_index)\n","        return x\n","\n","    def reset_parameters(self):\n","        self.conv1.reset_parameters()\n","        self.conv2.reset_parameters()\n","        self.conv3.reset_parameters()"]},{"cell_type":"markdown","metadata":{"id":"rVrCwCkmoDp6"},"source":["Link predictor (predicts using dot product)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rXSMqpLOoDp7"},"outputs":[],"source":["class LinkPredictor(torch.nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x_track, x_playlist, track_playlist_edge):\n","        track_embedding = x_track[track_playlist_edge[0]]\n","        playlist_embedding = x_playlist[track_playlist_edge[1]]\n","\n","        # Apply dot-product to get a prediction per supervision edge:\n","        return (track_embedding * playlist_embedding).sum(dim=-1)"]},{"cell_type":"markdown","metadata":{"id":"pmwS3b9QoDp7"},"source":["Full model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xJq0eycRoDp8"},"outputs":[],"source":["class HeteroModel(torch.nn.Module):\n","    def __init__(self, hidden_channels, node_features, metadata):\n","        super().__init__()\n","        self.node_lin = {\n","            k: torch.nn.Linear(v.shape[1], hidden_channels).to(device) for k, v in node_features.items()\n","        }\n","        self.gnn = GNN(hidden_channels).to(device)\n","        self.gnn = torch_geometric.nn.to_hetero(self.gnn, metadata=metadata).to(device)\n","        self.classifier = LinkPredictor().to(device)\n","    \n","    def embed(self, data):\n","        x_dict = {\n","            k: self.node_lin[k](v) for k, v in data.x_dict.items()\n","        }\n","        x_dict = self.gnn(x_dict, data.edge_index_dict)\n","        return x_dict\n","\n","    def forward(self, data):\n","        x_dict = self.embed(data)\n","        pred = self.classifier(\n","            x_dict[\"track\"],\n","            x_dict[\"playlist\"],\n","            data[\"track\", \"contains\", \"playlist\"].edge_label_index,\n","        )\n","        return pred\n","\n","    def reset_parameters(self):\n","        for _, v in self.node_lin.items():\n","            torch.nn.init.xavier_uniform_(v.weight)\n","        self.gnn.reset_parameters()\n","\n","def dummy_generator(source):\n","    for e in source:\n","        yield e"]},{"cell_type":"markdown","metadata":{"id":"hS7LthNeoDp8"},"source":["Model train and test functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AyjGejvtoDp9"},"outputs":[],"source":["\n","outs = []\n","\n","def test(model, data_test):\n","    with torch.no_grad():\n","        test_out = model(data_test.to(device)).to('cpu')\n","        truth = data_test[\"track\", \"contains\", \"playlist\"].edge_label.to('cpu')\n","\n","    test_loss = torch.nn.functional.mse_loss(\n","        test_out,\n","        truth\n","    )\n","    metric = BinaryAccuracy()\n","    metric.update(test_out, truth)\n","    return float(test_loss), metric.compute()\n","\n","def train(model, train_loader, optimizer, batch_wrapper=dummy_generator):\n","    model.train()\n","\n","    accuracy = 0\n","\n","    total_examples = total_loss = 0\n","    for batch in batch_wrapper(train_loader):\n","        optimizer.zero_grad()\n","        \n","        out = model(batch)\n","        truth = batch[\"track\", \"contains\", \"playlist\"].edge_label\n","\n","        loss = torch.nn.functional.mse_loss(\n","            out, truth\n","        )\n","        loss.backward()\n","        optimizer.step()\n","\n","        aute_gledam = out.to('cpu')\n","\n","        outs.append(aute_gledam)\n","\n","        metric = BinaryAccuracy()\n","        metric.update(aute_gledam, truth.to('cpu'))\n","        accuracy += metric.compute() * len(out)\n","\n","        total_examples += len(out)\n","        total_loss += float(loss) * len(out)\n","\n","    return total_loss / total_examples, accuracy / total_examples"]},{"cell_type":"markdown","metadata":{"id":"p7M9qnJOoDp9"},"source":["# Train the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lHf919yRoDp-","outputId":"74ce9264-bffb-404c-e3d2-469f5f31cc86"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.09files/s]\n"]},{"name":"stdout","output_type":"stream","text":["track-artist spotify:track:7o2CTH4ctstm8TNelqjb51 spotify:artist:3qm84nBOXUEQ2vnTfUTTFC\n"]}],"source":["G = load_graph()\n","ghetero = nx2hetero(G)\n","data_train, data_val, data_test = ghetero2datasets(ghetero)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yLd2D-aEpiq-"},"outputs":[],"source":["# create training mask for playlist nodes\n","train_mask = torch.zeros(ghetero[\"playlist\"].x.shape[0], dtype=torch.bool)\n","train_mask[torch.randperm(train_mask.shape[0])[:int(train_mask.shape[0]*0.8)]] = True\n","\n","ghetero[\"playlist\"].train_mask = train_mask\n","\n","ghetero[\"playlist\"].y = torch.LongTensor([1]*ghetero[\"playlist\"].x.shape[0]).to(device)\n","\n","model = HeteroModel(64, ghetero.x_dict, ghetero.metadata()).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.00001)\n","edge_label_index = data_train[\"track\", \"contains\", \"playlist\"].edge_label_index\n","edge_label = data_train[\"track\", \"contains\", \"playlist\"].edge_label\n","\n","train_loader = torch_geometric.loader.LinkNeighborLoader(\n","    data=data_train,\n","    num_neighbors=[-1],\n","    neg_sampling_ratio=0.5,\n","    edge_label_index=((\"track\", \"contains\", \"playlist\"), edge_label_index),\n","    edge_label=edge_label,\n","    batch_size=20000,\n","    shuffle=True,\n","    transform=T.ToDevice(device)\n",")\n","\n","epoch = 2000\n","render_graph = True\n","\n","losses = []\n","accuracies = []\n","test_losses = []\n","test_accuracies = []\n","\n","epoch_iter = tqdm(range(epoch), unit='epoch', desc='Training', bar_format='{desc:<5.5}{percentage:3.0f}%|{bar:10}{r_bar}')\n","for i in epoch_iter:\n","    loss, accuracy = train(model, train_loader, optimizer)\n","    losses.append(loss)\n","    accuracies.append(accuracy)\n","    test_loss, test_acc = test(model, data_val)\n","    test_losses.append(test_loss)\n","    test_accuracies.append(test_acc)\n","    epoch_iter.set_postfix_str(f\"Train Loss: {loss:.4f}, Train Accuracy {accuracy:.4f}, Valid Loss {test_loss:.4f}, Valid Accuracy {test_acc:.4f}\")\n"]},{"cell_type":"markdown","metadata":{"id":"kCLqrI9aplfr"},"source":["Render learning graph"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A18XjnNpoDqA","outputId":"c67d6f01-a807-4360-8593-68cabc54eea1"},"outputs":[],"source":["plt.clf()\n","# add labels\n","plt.plot(np.arange(len(accuracies)), accuracies, label='Accuracy')\n","plt.plot(np.arange(len(losses)), losses, label='Loss')\n","plt.plot(np.arange(len(test_losses)), test_losses, label='Test Loss')\n","plt.plot(np.arange(len(test_accuracies)), test_accuracies, label='Test Accuracy')\n","\n","# start plot at 0\n","plt.ylim(0, 1)\n","plt.legend()\n","plt.show()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"fdd1bf0cdef9f431ef204eb65428406a6292ed13583a3a7833f3ab005ff2b93a"}}},"nbformat":4,"nbformat_minor":0}
