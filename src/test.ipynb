{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will train a GNN to perform link prediction on a heterogenous graph from the Spotify Million Playlists dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '/home/yon/jupyter-server/mlg/src/')\n",
    "\n",
    "import loader\n",
    "import config\n",
    "import model as M\n",
    "import preprocessing\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import random\n",
    "import torch_geometric\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheval.metrics import BinaryAccuracy\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch_geometric.nn.SAGEConv((-1, -1), hidden_channels, normalize=True)\n",
    "        self.conv2 = torch_geometric.nn.SAGEConv((-1, -1), hidden_channels, normalize=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "class LinkPredictor(torch.nn.Module):\n",
    "    def forward(self, x_track, x_playlist, track_playlist_edge):\n",
    "        track_embedding = x_track[track_playlist_edge[0]]\n",
    "        playlist_embedding = x_playlist[track_playlist_edge[1]]\n",
    "\n",
    "        #print(playlist_embedding)\n",
    "\n",
    "        # Apply dot-product to get a prediction per supervision edge:\n",
    "        return (playlist_embedding * track_embedding).sum(dim=-1)\n",
    "\n",
    "class HeteroModel(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, node_features, metadata):\n",
    "        super().__init__()\n",
    "        # Since the dataset does not come with rich features, we also learn two\n",
    "        # embedding matrices for users and movies:\n",
    "\n",
    "        self.node_lin = {\n",
    "            k: torch.nn.Linear(v.shape[1], hidden_channels) for k, v in node_features.items()\n",
    "        }\n",
    "\n",
    "        for _, v in self.node_lin.items():\n",
    "            torch.nn.init.xavier_uniform_(v.weight)\n",
    "        \n",
    "        # Instantiate homogeneous GNN:\n",
    "        self.gnn = GNN(hidden_channels)\n",
    "        # Convert GNN model into a heterogeneous variant:\n",
    "        self.gnn = torch_geometric.nn.to_hetero(self.gnn, metadata=metadata)\n",
    "\n",
    "        self.classifier = LinkPredictor()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x_dict = {\n",
    "            k: self.node_lin[k](v) for k, v in data.x_dict.items()\n",
    "        }\n",
    "\n",
    "        x_dict = self.gnn(x_dict, data.edge_index_dict)\n",
    "        pred = self.classifier(\n",
    "            x_dict[\"track\"],\n",
    "            x_dict[\"playlist\"],\n",
    "            data[\"track\", \"contains\", \"playlist\"].edge_label_index,\n",
    "        )\n",
    "        return pred\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for _, v in self.node_lin.items():\n",
    "            torch.nn.init.xavier_uniform_(v.weight)\n",
    "        self.gnn.reset_parameters()\n",
    "\n",
    "def dummy_generator(source):\n",
    "    for e in source:\n",
    "        yield e\n",
    "\n",
    "def train(model, train_loader, optimizer, batch_wrapper=dummy_generator):\n",
    "    model.train()\n",
    "\n",
    "    accuracy = 0\n",
    "\n",
    "    total_examples = total_loss = 0\n",
    "    for i, batch in enumerate(batch_wrapper(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model(batch)\n",
    "        truth = batch[\"track\", \"contains\", \"playlist\"].edge_label\n",
    "\n",
    "\n",
    "        if(i % 10 == 0):\n",
    "            #print(out[:10])\n",
    "            #print(batch[\"track\", \"contains\", \"playlist\"].edge_label[:10])\n",
    "            pass\n",
    "        loss = torch.nn.functional.mse_loss(\n",
    "            out, truth\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        metric = BinaryAccuracy()\n",
    "        metric.update(out, truth)\n",
    "        accuracy += metric.compute() * len(out)\n",
    "\n",
    "        total_examples += len(out)\n",
    "        total_loss += float(loss) * len(out)\n",
    "\n",
    "    return total_loss / total_examples, accuracy / total_examples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm spotify_million_playlist_dataset/pickles/G_example.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickled ghetero not found, generating anew ...\n",
      "Pickled G not found, generating anew ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.07s/files]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G generated, pickle saved to spotify_million_playlist_dataset/pickles/G_example.pkl\n",
      "[1, False, 39, 40, 11, 9631768, 29]\n",
      "ghetero generated, pickle saved to spotify_million_playlist_dataset/pickles/ghetero_example.pkl\n",
      "Pickled datasets not found, generating anew ...\n",
      "Loading ghetero from pickle ...\n",
      "datasets generated, pickle saved to spotify_million_playlist_dataset/pickles/datasets_example.pkl\n"
     ]
    }
   ],
   "source": [
    "ghetero = loader.get_ghetero(True, config)\n",
    "data_train, data_val, data_test = loader.get_datasets(True, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training mask for playlist nodes\n",
    "train_mask = torch.zeros(ghetero[\"playlist\"].x.shape[0], dtype=torch.bool)\n",
    "train_mask[torch.randperm(train_mask.shape[0])[:int(train_mask.shape[0]*0.8)]] = True\n",
    "\n",
    "ghetero[\"playlist\"].train_mask = train_mask\n",
    "\n",
    "ghetero[\"playlist\"].y = torch.LongTensor([1]*ghetero[\"playlist\"].x.shape[0])\n",
    "\n",
    "model = HeteroModel(64, ghetero.x_dict, ghetero.metadata())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "edge_label_index = data_train[\"track\", \"contains\", \"playlist\"].edge_label_index\n",
    "edge_label = data_train[\"track\", \"contains\", \"playlist\"].edge_label\n",
    "train_loader = torch_geometric.loader.LinkNeighborLoader(\n",
    "    data=data_train,\n",
    "    num_neighbors=[20, 10],\n",
    "    neg_sampling_ratio=2.0,\n",
    "    edge_label_index=((\"track\", \"contains\", \"playlist\"), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mplaylist\u001b[0m={ x=[1000, 1] },\n",
       "  \u001b[1mtrack\u001b[0m={ x=[35289, 1] },\n",
       "  \u001b[1martist\u001b[0m={ x=[10091, 1] },\n",
       "  \u001b[1malbum\u001b[0m={ x=[20469, 1] },\n",
       "  \u001b[1m(track, contains, playlist)\u001b[0m={\n",
       "    edge_index=[2, 37146],\n",
       "    edge_label=[15919],\n",
       "    edge_label_index=[2, 15919]\n",
       "  },\n",
       "  \u001b[1m(track, includes, album)\u001b[0m={ edge_index=[2, 35289] },\n",
       "  \u001b[1m(track, authors, artist)\u001b[0m={ edge_index=[2, 35289] },\n",
       "  \u001b[1m(playlist, rev_contains, track)\u001b[0m={ edge_index=[2, 37146] },\n",
       "  \u001b[1m(album, rev_includes, track)\u001b[0m={ edge_index=[2, 35289] },\n",
       "  \u001b[1m(artist, rev_authors, track)\u001b[0m={ edge_index=[2, 35289] }\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 125/125 [00:05<00:00, 24.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.2746, Accuracy 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 125/125 [00:04<00:00, 25.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100, Loss: 0.2120, Accuracy 0.6809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 125/125 [00:04<00:00, 25.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100, Loss: 0.2087, Accuracy 0.6950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 125/125 [00:04<00:00, 25.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100, Loss: 0.2060, Accuracy 0.6809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 125/125 [00:04<00:00, 25.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100, Loss: 0.2047, Accuracy 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 125/125 [00:04<00:00, 25.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100, Loss: 0.2049, Accuracy 0.7163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 125/125 [00:04<00:00, 25.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100, Loss: 0.2038, Accuracy 0.6738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 125/125 [00:04<00:00, 25.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100, Loss: 0.2025, Accuracy 0.7092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 125/125 [00:04<00:00, 25.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100, Loss: 0.1998, Accuracy 0.6879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 125/125 [00:04<00:00, 25.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 0.1984, Accuracy 0.6950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 125/125 [00:04<00:00, 25.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100, Loss: 0.1989, Accuracy 0.6596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 125/125 [00:04<00:00, 25.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100, Loss: 0.1981, Accuracy 0.7021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 125/125 [00:04<00:00, 25.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100, Loss: 0.1978, Accuracy 0.6809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 125/125 [00:05<00:00, 25.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100, Loss: 0.1961, Accuracy 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 125/125 [00:04<00:00, 25.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100, Loss: 0.1962, Accuracy 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 125/125 [00:04<00:00, 25.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100, Loss: 0.1965, Accuracy 0.6950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|████████████████████████████████████████████████████████▏              | 99/125 [00:03<00:01, 25.10it/s]"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "epoch = 100\n",
    "\n",
    "for i in range(epoch):\n",
    "    loss, accuracy = train(model, train_loader, optimizer, batch_wrapper=tqdm.tqdm)\n",
    "    print(f\"Epoch {i+1}/{epoch}, Loss: {loss:.4f}, Accuracy {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fdd1bf0cdef9f431ef204eb65428406a6292ed13583a3a7833f3ab005ff2b93a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
