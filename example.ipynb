{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import OGB_MAG\n",
    "\n",
    "dataset = OGB_MAG(root='./data', preprocess='metapath2vec')\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mpaper\u001b[0m={\n",
       "    x=[736389, 128],\n",
       "    year=[736389],\n",
       "    y=[736389],\n",
       "    train_mask=[736389],\n",
       "    val_mask=[736389],\n",
       "    test_mask=[736389]\n",
       "  },\n",
       "  \u001b[1mauthor\u001b[0m={ x=[1134649, 128] },\n",
       "  \u001b[1minstitution\u001b[0m={ x=[8740, 128] },\n",
       "  \u001b[1mfield_of_study\u001b[0m={ x=[59965, 128] },\n",
       "  \u001b[1m(author, affiliated_with, institution)\u001b[0m={ edge_index=[2, 1043998] },\n",
       "  \u001b[1m(author, writes, paper)\u001b[0m={ edge_index=[2, 7145660] },\n",
       "  \u001b[1m(paper, cites, paper)\u001b[0m={ edge_index=[2, 5416271] },\n",
       "  \u001b[1m(paper, has_topic, field_of_study)\u001b[0m={ edge_index=[2, 7505078] }\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "def nx2hetero(G):\n",
    "\tname2int = dict()\n",
    "\tint2name = dict()\n",
    "\tfor i,name in enumerate(list(G.nodes)):\n",
    "\t\tname2int[name] = i\n",
    "\t\tint2name[i] = name\n",
    "\n",
    "\tnode_types = set([node[1][\"node_type\"] for node in G.nodes(data=True)])\n",
    "\tnodes_by_type = dict()\n",
    "\tfor node_type in node_types:\n",
    "\t\tnodes_by_type[node_type] = [node[1] for node in list(G.nodes(data=True)) if node[1][\"node_type\"] == node_type][:10]\n",
    "\tnodes_by_type\n",
    "\n",
    "\t# build node index\n",
    "\tplaylists = []\n",
    "\ttracks = []\n",
    "\tnum_artists = 0\n",
    "\tnum_albums = 0\n",
    "\tfor node in G.nodes(data=True):\n",
    "\t\tt = node[1][\"node_type\"]\n",
    "\t\tif t == \"playlist\":\n",
    "\t\t\tplaylists += [node[1][\"num_followers\"]]\n",
    "\t\telif t == \"track\":\n",
    "\t\t\ttracks += [node[1][\"duration\"]]\n",
    "\t\telif t == \"artist\":\n",
    "\t\t\tnum_artists += 1\n",
    "\t\telif t == \"album\":\n",
    "\t\t\tnum_albums += 1\n",
    "\n",
    "\t# build edge_index\n",
    "\tplaylist_track = []\n",
    "\talbum_track = []\n",
    "\tartist_track = []\n",
    "\n",
    "\tfor edge in G.edges(data=True):\n",
    "\t\tif G[edge[0]][edge[1]][\"edge_type\"] == \"track-playlist\":\n",
    "\t\t\tplaylist_track += [(name2int[edge[0]], name2int[edge[1]])]\n",
    "\t\telif G[edge[0]][edge[1]][\"edge_type\"] == \"track-album\":\n",
    "\t\t\talbum_track += [(name2int[edge[0]], name2int[edge[1]])]\n",
    "\t\telif G[edge[0]][edge[1]][\"edge_type\"] == \"track-artist\":\n",
    "\t\t\tartist_track += [(name2int[edge[0]], name2int[edge[1]])]\n",
    "\t\t\n",
    "\t\tnode_start = edge[0].split(\":\")[1]\n",
    "\t\tnode_end = edge[1].split(\":\")[1]\n",
    "\n",
    "\t\tif node_end != \"track\":\n",
    "\t\t\tnode_start, node_end = node_end, node_start\t\t\n",
    "\n",
    "\t# construct HeteroData\n",
    "\thetero = torch_geometric.data.HeteroData()\n",
    "\n",
    "\t# add initial node features\n",
    "\thetero[\"playlist\"].x = torch.IntTensor(playlists).reshape(-1,1)\n",
    "\thetero[\"track\"].x = torch.IntTensor(tracks).reshape(-1,1)\n",
    "\thetero[\"artist\"].x = torch.IntTensor([1 for _ in range(num_artists)]).reshape(-1,1)\n",
    "\thetero[\"album\"].x = torch.IntTensor([1 for _ in range(num_albums)]).reshape(-1,1)\n",
    "\n",
    "\t# add edge indices\n",
    "\thetero[\"playlist\", \"contains\", \"track\"].edge_index = torch.tensor(playlist_track).t()\n",
    "\thetero[\"album\", \"includes\", \"track\"].edge_index = torch.tensor(album_track).t()\n",
    "\thetero[\"artist\", \"authors\", \"track\"].edge_index = torch.tensor(artist_track).t()\n",
    "\n",
    "\treturn hetero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "base = \"spotify_million_playlist_dataset\"\n",
    "pickles = base + \"/pickles\"\n",
    "graph_path = os.path.join(pickles, \"G_example.pkl\")\n",
    "\n",
    "G = pickle.load(open(graph_path, \"rb\"))\n",
    "\n",
    "our_data = nx2hetero(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training mask for playlist nodes\n",
    "train_mask = torch.zeros(our_data[\"playlist\"].x.shape[0], dtype=torch.bool)\n",
    "train_mask[torch.randperm(train_mask.shape[0])[:int(train_mask.shape[0]*0.8)]] = True\n",
    "\n",
    "our_data[\"playlist\"].train_mask = train_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mplaylist\u001b[0m={\n",
       "    x=[1000, 1],\n",
       "    train_mask=[1000]\n",
       "  },\n",
       "  \u001b[1mtrack\u001b[0m={ x=[35289, 1] },\n",
       "  \u001b[1martist\u001b[0m={ x=[10091, 1] },\n",
       "  \u001b[1malbum\u001b[0m={ x=[20469, 1] },\n",
       "  \u001b[1m(playlist, contains, track)\u001b[0m={ edge_index=[2, 66331] },\n",
       "  \u001b[1m(album, includes, track)\u001b[0m={ edge_index=[2, 35289] },\n",
       "  \u001b[1m(artist, authors, track)\u001b[0m={ edge_index=[2, 35289] }\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['playlist', 'track', 'artist', 'album'],\n",
       " [('playlist', 'contains', 'track'),\n",
       "  ('album', 'includes', 'track'),\n",
       "  ('artist', 'authors', 'track'),\n",
       "  ('track', 'rev_contains', 'playlist'),\n",
       "  ('track', 'rev_includes', 'album'),\n",
       "  ('track', 'rev_authors', 'artist')])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_data.metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = our_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.is_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 136909], x=[66849, 1], train_mask=[66849], node_type=[66849], edge_type=[136909])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homogeneous_data = data.to_homogeneous()\n",
    "homogeneous_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "\n",
    "data = T.ToUndirected()(data)\n",
    "# data = T.NormalizeFeatures()(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.is_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import OGB_MAG\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = GNN(hidden_channels=64, out_channels=dataset.num_classes)\n",
    "model = to_hetero(model, data.metadata(), aggr='sum')\n",
    "# model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'edge_index' of edge type ('playlist', 'contains', 'track') contains larger source indices than the number of nodes (1000) of this node type in 'HeteroData' (found 66694)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data\u001b[39m.\u001b[39;49mvalidate()\n",
      "File \u001b[0;32m~/jupyter-server/venv/lib/python3.10/site-packages/torch_geometric/data/hetero_data.py:381\u001b[0m, in \u001b[0;36mHeteroData.validate\u001b[0;34m(self, raise_on_error)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[39mif\u001b[39;00m (num_src_nodes \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    379\u001b[0m         \u001b[39mand\u001b[39;00m store\u001b[39m.\u001b[39medge_index[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmax() \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m num_src_nodes):\n\u001b[1;32m    380\u001b[0m     status \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 381\u001b[0m     warn_or_raise(\n\u001b[1;32m    382\u001b[0m         \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39medge_index\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m of edge type \u001b[39;49m\u001b[39m{\u001b[39;49;00medge_type\u001b[39m}\u001b[39;49;00m\u001b[39m contains \u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m    383\u001b[0m         \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mlarger source indices than the number of nodes \u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m    384\u001b[0m         \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m(\u001b[39;49m\u001b[39m{\u001b[39;49;00mnum_src_nodes\u001b[39m}\u001b[39;49;00m\u001b[39m) of this node type in \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mcls_name\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m    385\u001b[0m         \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m(found \u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mint\u001b[39;49m(store\u001b[39m.\u001b[39;49medge_index[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mmax())\u001b[39m}\u001b[39;49;00m\u001b[39m)\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    386\u001b[0m         raise_on_error)\n\u001b[1;32m    388\u001b[0m \u001b[39mif\u001b[39;00m (num_dst_nodes \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    389\u001b[0m         \u001b[39mand\u001b[39;00m store\u001b[39m.\u001b[39medge_index[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mmax() \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m num_dst_nodes):\n\u001b[1;32m    390\u001b[0m     status \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyter-server/venv/lib/python3.10/site-packages/torch_geometric/data/data.py:943\u001b[0m, in \u001b[0;36mwarn_or_raise\u001b[0;34m(msg, raise_on_error)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwarn_or_raise\u001b[39m(msg: \u001b[39mstr\u001b[39m, raise_on_error: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    942\u001b[0m     \u001b[39mif\u001b[39;00m raise_on_error:\n\u001b[0;32m--> 943\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m    944\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    945\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: 'edge_index' of edge type ('playlist', 'contains', 'track') contains larger source indices than the number of nodes (1000) of this node type in 'HeteroData' (found 66694)"
     ]
    }
   ],
   "source": [
    "data.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import OGB_MAG\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "# transform = T.ToUndirected()  # Add reverse edge types.\n",
    "# data = OGB_MAG(root='./data', preprocess='metapath2vec', transform=transform)[0]\n",
    "\n",
    "train_loader = NeighborLoader(\n",
    "    data,\n",
    "    # Sample 15 neighbors for each node and each edge type for 2 iterations:\n",
    "    num_neighbors=[15] * 2,\n",
    "    # num_neighbors = {key: [15] * 2 for key in data.edge_types} will sample different ammounts for each node type\n",
    "    # Use a batch size of 128 for sampling training nodes of type \"paper\":\n",
    "    batch_size=128,\n",
    "    input_nodes=('playlist', data['playlist'].train_mask),\n",
    ")\n",
    "\n",
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mpaper\u001b[0m={\n",
       "    x=[20796, 128],\n",
       "    year=[20796],\n",
       "    y=[20796],\n",
       "    train_mask=[20796],\n",
       "    val_mask=[20796],\n",
       "    test_mask=[20796],\n",
       "    input_id=[128],\n",
       "    batch_size=128\n",
       "  },\n",
       "  \u001b[1mauthor\u001b[0m={ x=[4454, 128] },\n",
       "  \u001b[1minstitution\u001b[0m={ x=[306, 128] },\n",
       "  \u001b[1mfield_of_study\u001b[0m={ x=[2584, 128] },\n",
       "  \u001b[1m(author, affiliated_with, institution)\u001b[0m={ edge_index=[2, 0] },\n",
       "  \u001b[1m(author, writes, paper)\u001b[0m={ edge_index=[2, 5916] },\n",
       "  \u001b[1m(paper, cites, paper)\u001b[0m={ edge_index=[2, 11751] },\n",
       "  \u001b[1m(paper, has_topic, field_of_study)\u001b[0m={ edge_index=[2, 10573] },\n",
       "  \u001b[1m(institution, rev_affiliated_with, author)\u001b[0m={ edge_index=[2, 821] },\n",
       "  \u001b[1m(paper, rev_writes, author)\u001b[0m={ edge_index=[2, 5484] },\n",
       "  \u001b[1m(field_of_study, rev_has_topic, paper)\u001b[0m={ edge_index=[2, 10432] }\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_examples = total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        # batch = batch.to('cuda:0')\n",
    "        batch_size = batch['paper'].batch_size\n",
    "        out = model(batch.x_dict, batch.edge_index_dict)\n",
    "        loss = F.cross_entropy(out['paper'][:batch_size],\n",
    "                               batch['paper'].y[:batch_size])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_examples += batch_size\n",
    "        print(f'Loss: {loss:.4f}')\n",
    "        total_loss += float(loss) * batch_size\n",
    "\n",
    "    return total_loss / total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`MessagePassing.propagate` only supports integer tensors of shape `[2, num_messages]`, `torch_sparse.SparseTensor` or `torch.sparse.Tensor` for argument `edge_index`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train()\n",
      "Cell \u001b[0;32mIn[68], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39m# batch = batch.to('cuda:0')\u001b[39;00m\n\u001b[1;32m      8\u001b[0m batch_size \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39mpaper\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mbatch_size\n\u001b[0;32m----> 9\u001b[0m out \u001b[39m=\u001b[39m model(batch\u001b[39m.\u001b[39;49mx_dict, batch\u001b[39m.\u001b[39;49medge_index_dict)\n\u001b[1;32m     10\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy(out[\u001b[39m'\u001b[39m\u001b[39mpaper\u001b[39m\u001b[39m'\u001b[39m][:batch_size],\n\u001b[1;32m     11\u001b[0m                        batch[\u001b[39m'\u001b[39m\u001b[39mpaper\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39my[:batch_size])\n\u001b[1;32m     12\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/jupyter-server/venv/lib64/python3.10/site-packages/torch/fx/graph_module.py:658\u001b[0m, in \u001b[0;36mGraphModule.recompile.<locals>.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_wrapped\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 658\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wrapped_call(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/jupyter-server/venv/lib64/python3.10/site-packages/torch/fx/graph_module.py:277\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    276\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 277\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/jupyter-server/venv/lib64/python3.10/site-packages/torch/fx/graph_module.py:267\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcls_call(obj, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    266\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 267\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcls, obj)\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    269\u001b[0m     \u001b[39massert\u001b[39;00m e\u001b[39m.\u001b[39m__traceback__\n",
      "File \u001b[0;32m~/jupyter-server/venv/lib64/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m<eval_with_key>.7:17\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     15\u001b[0m edge_index__track__rev_includes__album \u001b[39m=\u001b[39m edge_index_dict\u001b[39m.\u001b[39mget((\u001b[39m'\u001b[39m\u001b[39mtrack\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrev_includes\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39malbum\u001b[39m\u001b[39m'\u001b[39m), \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m edge_index__track__rev_authors__artist \u001b[39m=\u001b[39m edge_index_dict\u001b[39m.\u001b[39mget((\u001b[39m'\u001b[39m\u001b[39mtrack\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrev_authors\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39martist\u001b[39m\u001b[39m'\u001b[39m), \u001b[39mNone\u001b[39;00m);  edge_index_dict \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m conv1__track1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1\u001b[39m.\u001b[39;49mplaylist__contains__track((x__playlist, x__track), edge_index__playlist__contains__track)\n\u001b[1;32m     18\u001b[0m conv1__track2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1\u001b[39m.\u001b[39malbum__includes__track((x__album, x__track), edge_index__album__includes__track)\n\u001b[1;32m     19\u001b[0m conv1__track3 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1\u001b[39m.\u001b[39martist__authors__track((x__artist, x__track), edge_index__artist__authors__track)\n",
      "File \u001b[0;32m~/jupyter-server/venv/lib64/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/jupyter-server/venv/lib/python3.10/site-packages/torch_geometric/nn/conv/sage_conv.py:131\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m    128\u001b[0m     x \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin(x[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mrelu(), x[\u001b[39m1\u001b[39m])\n\u001b[1;32m    130\u001b[0m \u001b[39m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(edge_index, x\u001b[39m=\u001b[39;49mx, size\u001b[39m=\u001b[39;49msize)\n\u001b[1;32m    132\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin_l(out)\n\u001b[1;32m    134\u001b[0m x_r \u001b[39m=\u001b[39m x[\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/jupyter-server/venv/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:392\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    390\u001b[0m         edge_index, size, kwargs \u001b[39m=\u001b[39m res\n\u001b[0;32m--> 392\u001b[0m size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__check_input__(edge_index, size)\n\u001b[1;32m    394\u001b[0m \u001b[39m# Run \"fused\" message and aggregation (if applicable).\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[39mif\u001b[39;00m is_sparse(edge_index) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuse \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexplain:\n",
      "File \u001b[0;32m~/jupyter-server/venv/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:216\u001b[0m, in \u001b[0;36mMessagePassing.__check_input__\u001b[0;34m(self, edge_index, size)\u001b[0m\n\u001b[1;32m    213\u001b[0m         the_size[\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m size[\u001b[39m1\u001b[39m]\n\u001b[1;32m    214\u001b[0m     \u001b[39mreturn\u001b[39;00m the_size\n\u001b[0;32m--> 216\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    217\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39m`MessagePassing.propagate` only supports integer tensors of \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    218\u001b[0m      \u001b[39m'\u001b[39m\u001b[39mshape `[2, num_messages]`, `torch_sparse.SparseTensor` or \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    219\u001b[0m      \u001b[39m'\u001b[39m\u001b[39m`torch.sparse.Tensor` for argument `edge_index`.\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[0;31mValueError\u001b[0m: `MessagePassing.propagate` only supports integer tensors of shape `[2, num_messages]`, `torch_sparse.SparseTensor` or `torch.sparse.Tensor` for argument `edge_index`."
     ]
    }
   ],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
