{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will train a GNN to perform link prediction on a heterogenous graph from the Spotify Million Playlists dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/yon/jupyter-server/venv/lib64/python3.10/site-packages (1.24.2)\n",
      "Requirement already satisfied: iprogress in /home/yon/jupyter-server/venv/lib/python3.10/site-packages (0.4)\n",
      "Requirement already satisfied: tqdm in /home/yon/jupyter-server/venv/lib/python3.10/site-packages (4.64.1)\n",
      "Requirement already satisfied: networkx in /home/yon/jupyter-server/venv/lib/python3.10/site-packages (3.0)\n",
      "Requirement already satisfied: torch_geometric in /home/yon/jupyter-server/venv/lib/python3.10/site-packages (2.2.0)\n",
      "Requirement already satisfied: six in /home/yon/jupyter-server/venv/lib/python3.10/site-packages (from iprogress) (1.16.0)\n",
      "Requirement already satisfied: pyparsing in /home/yon/jupyter-server/venv/lib/python3.10/site-packages (from torch_geometric) (3.0.9)\n",
      "Requirement already satisfied: scikit-learn in /home/yon/jupyter-server/venv/lib64/python3.10/site-packages (from torch_geometric) (1.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/yon/jupyter-server/venv/lib/python3.10/site-packages (from torch_geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in /home/yon/jupyter-server/venv/lib/python3.10/site-packages (from torch_geometric) (2.28.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/yon/jupyter-server/venv/lib64/python3.10/site-packages (from torch_geometric) (5.9.4)\n",
      "Requirement already satisfied: scipy in /home/yon/jupyter-server/venv/lib64/python3.10/site-packages (from torch_geometric) (1.10.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/yon/jupyter-server/venv/lib64/python3.10/site-packages (from jinja2->torch_geometric) (2.1.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/yon/jupyter-server/venv/lib/python3.10/site-packages (from requests->torch_geometric) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/yon/jupyter-server/venv/lib64/python3.10/site-packages (from requests->torch_geometric) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/yon/jupyter-server/venv/lib/python3.10/site-packages (from requests->torch_geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/yon/jupyter-server/venv/lib/python3.10/site-packages (from requests->torch_geometric) (1.26.14)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/yon/jupyter-server/venv/lib/python3.10/site-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/yon/jupyter-server/venv/lib/python3.10/site-packages (from scikit-learn->torch_geometric) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy iprogress tqdm networkx torch_geometric\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary imports (delete later)\n",
    "from pprint import pprint\n",
    "import random\n",
    "# http://192.168.0.103:8888/?token=klobasa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "base = \"../spotify_million_playlist_dataset\"\n",
    "pickles = base + \"/pickles\"\n",
    "\n",
    "# full dataset\n",
    "dataset_path = base + \"/data\"\n",
    "pickled_graph = pickles + \"/G.pkl\"\n",
    "pickled_datasets = pickles + \"/datasets.pkl\"\n",
    "pickled_ghetero = pickles + \"/ghetero.pkl\"\n",
    "\n",
    "# example dataset (override above)\n",
    "# dataset_path = base + \"/example\"\n",
    "# pickled_graph = pickles + \"/G_example.pkl\"\n",
    "# pickled_datasets = pickles + \"/datasets_example.pkl\"\n",
    "# pickled_ghetero = pickles + \"/ghetero_example.pkl\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(dataset_path=dataset_path):\n",
    "    \"\"\"Load a nx.Graph from disk.\"\"\"\n",
    "    filenames = os.listdir(dataset_path)\n",
    "    G = nx.DiGraph()\n",
    "    for i in tqdm(range(len(filenames)), unit=\"files\"):\n",
    "        with open(os.path.join(dataset_path, filenames[i])) as json_file:\n",
    "            playlists = json.load(json_file)[\"playlists\"]\n",
    "            for playlist in playlists:\n",
    "                playlist_name = f\"spotify:playlist:{playlist['pid']}\"\n",
    "                G.add_node(playlist_name, node_type=\"playlist\", num_followers=playlist[\"num_followers\"])\n",
    "                for track in playlist[\"tracks\"]:\n",
    "                    G.add_node(track[\"track_uri\"], node_type=\"track\", duration=track[\"duration_ms\"])\n",
    "                    G.add_node(track[\"album_uri\"], node_type=\"album\")\n",
    "                    G.add_node(track[\"artist_uri\"], node_type=\"artist\")\n",
    "\n",
    "                    G.add_edge(track[\"track_uri\"], playlist_name, edge_type=\"track-playlist\")\n",
    "                    G.add_edge(track[\"track_uri\"], track[\"album_uri\"], edge_type=\"track-album\")\n",
    "                    G.add_edge(track[\"track_uri\"], track[\"artist_uri\"], edge_type=\"track-artist\")\n",
    "    return G\n",
    "\n",
    "def nx2hetero(graph_getter):\n",
    "    G = graph_getter\n",
    "    \"\"\"Convert a nx.Graph into a torch_geometric.data.HeteroData object.\"\"\"\n",
    "    ids_by_type = {\n",
    "        \"playlist\": {},\n",
    "        \"track\": {},\n",
    "        \"artist\": {},\n",
    "        \"album\": {}\n",
    "    }\n",
    "    \n",
    "    def node_id(node_type, id):\n",
    "        d = ids_by_type[node_type]\n",
    "        if id not in d:\n",
    "            d[id] = len(d)\n",
    "        return d[id]\n",
    "\n",
    "    node_features_by_type = {\n",
    "        \"playlist\": [],\n",
    "        \"track\": [],\n",
    "        \"artist\": [],\n",
    "        \"album\": []\n",
    "    }\n",
    "    for node in G.nodes(data=True):\n",
    "        t = node[1][\"node_type\"]\n",
    "        node_id(t, node[0])\n",
    "        if t == \"playlist\":\n",
    "            node_features_by_type[\"playlist\"] += [node[1][\"num_followers\"]]\n",
    "        elif t == \"track\":\n",
    "            node_features_by_type[\"track\"] += [node[1][\"duration\"]]\n",
    "        elif t == \"artist\":\n",
    "            node_features_by_type[\"artist\"] += [1]\n",
    "        elif t == \"album\":\n",
    "            node_features_by_type[\"album\"] += [1]\n",
    "\n",
    "    edge_index_by_type = {\n",
    "        (\"track\", \"contains\", \"playlist\"): [],\n",
    "        (\"track\", \"includes\", \"album\"): [],\n",
    "        (\"track\", \"authors\", \"artist\"): []\n",
    "    }\n",
    "    for edge in G.edges(data=True):\n",
    "        if G[edge[0]][edge[1]][\"edge_type\"] == \"track-playlist\":\n",
    "            s_id = node_id(\"track\", edge[0])\n",
    "            d_id = node_id(\"playlist\", edge[1])\n",
    "            edge_index_by_type[(\"track\", \"contains\", \"playlist\")] += [(s_id, d_id)]\n",
    "        elif G[edge[0]][edge[1]][\"edge_type\"] == \"track-album\":\n",
    "            s_id = node_id(\"track\", edge[0])\n",
    "            d_id = node_id(\"album\", edge[1])\n",
    "            edge_index_by_type[(\"track\", \"includes\", \"album\")] += [(s_id, d_id)]\n",
    "        elif G[edge[0]][edge[1]][\"edge_type\"] == \"track-artist\":\n",
    "            s_id = node_id(\"track\", edge[0])\n",
    "            d_id = node_id(\"artist\", edge[1])\n",
    "            edge_index_by_type[(\"track\", \"authors\", \"artist\")] += [(s_id, d_id)]\n",
    "\n",
    "    # construct HeteroData\n",
    "    hetero = torch_geometric.data.HeteroData()\n",
    "\n",
    "    # add initial node features\n",
    "    hetero[\"playlist\"].x = torch.FloatTensor(node_features_by_type[\"playlist\"]).reshape(-1,1)\n",
    "    hetero[\"track\"].x = torch.FloatTensor(node_features_by_type[\"track\"]).reshape(-1,1)\n",
    "    hetero[\"artist\"].x = torch.FloatTensor(node_features_by_type[\"artist\"]).reshape(-1,1)\n",
    "    hetero[\"album\"].x = torch.FloatTensor(node_features_by_type[\"album\"]).reshape(-1,1)\n",
    "\n",
    "    # add edge indices\n",
    "    hetero[\"track\", \"contains\", \"playlist\"].edge_index = torch.tensor(edge_index_by_type[(\"track\", \"contains\", \"playlist\")]).t()\n",
    "    hetero[\"track\", \"includes\", \"album\"].edge_index = torch.tensor(edge_index_by_type[(\"track\", \"includes\", \"album\")]).t()\n",
    "    hetero[\"track\", \"authors\", \"artist\"].edge_index = torch.tensor(edge_index_by_type[(\"track\", \"authors\", \"artist\")]).t()\n",
    "\n",
    "    # post-processing\n",
    "    hetero = torch_geometric.transforms.ToUndirected()(hetero)\n",
    "    hetero = torch_geometric.transforms.RemoveIsolatedNodes()(hetero)\n",
    "    assert hetero.validate()\n",
    "    return hetero\n",
    "\n",
    "def get_cached(var, pickled_filename, fallback, ignore_cache=False):\n",
    "    \"\"\"Get a variable from cache.\n",
    "    \n",
    "    First, check global memory (variable `var`).\n",
    "    If not found, check pickle (file `pickled_filename`).\n",
    "    If not found, generate anew (use `fallback` function).\n",
    "    \"\"\"\n",
    "    if not ignore_cache and var in globals():\n",
    "        print(f\"Using {var} from global memory ...\")\n",
    "        return globals()[var]\n",
    "    elif not ignore_cache and os.path.exists(pickled_filename):\n",
    "        print(f\"Loading {var} from pickle ...\")\n",
    "        return pickle.load(open(pickled_filename, \"rb\"))\n",
    "    else:\n",
    "        print(f\"Pickled {var} not found, generating anew ...\")\n",
    "        obj = fallback()\n",
    "        # pickle.dump(obj, open(pickled_filename, \"wb\"))\n",
    "        print(f\"{var} generated, pickle saved to {pickled_filename}\")\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm ../spotify_million_playlist_dataset/pickles/datasets_example.pkl\n",
    "# !rm ../spotify_million_playlist_dataset/pickles/G_example.pkl\n",
    "# !rm ../spotify_million_playlist_dataset/pickles/ghetero_example.pkl\n",
    "# !ls ../spotify_million_playlist_dataset/pickles/\n",
    "# del G\n",
    "# del ghetero\n",
    "# del datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ghetero2datasets(ghetero):\n",
    "    \"\"\"Split the dataset into train, validation and test sets.\"\"\"\n",
    "    transform = torch_geometric.transforms.RandomLinkSplit(\n",
    "        num_val=0.1,\n",
    "        num_test=0.1,\n",
    "        disjoint_train_ratio=0.3,\n",
    "        neg_sampling_ratio=2.0,\n",
    "        add_negative_train_samples=False,\n",
    "        edge_types=(\"track\", \"contains\", \"playlist\"),\n",
    "        rev_edge_types=(\"track\", \"rev_contains\", \"playlist\"), \n",
    "    )\n",
    "\n",
    "    return transform(ghetero)  # 3-tuple: data_train, data_val, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickled ghetero not found, generating anew ...\n",
      "Pickled G not found, generating anew ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.29files/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G generated, pickle saved to ../spotify_million_playlist_dataset/pickles/G_example.pkl\n",
      "ghetero generated, pickle saved to ../spotify_million_playlist_dataset/pickles/ghetero_example.pkl\n",
      "Pickled datasets not found, generating anew ...\n",
      "Using ghetero from global memory ...\n",
      "datasets generated, pickle saved to ../spotify_million_playlist_dataset/pickles/datasets_example.pkl\n",
      "Finished loading data.\n"
     ]
    }
   ],
   "source": [
    "get_g = lambda: get_cached(\"G\", pickled_graph, fallback=load_graph)\n",
    "get_ghetero = lambda: get_cached(\"ghetero\", pickled_ghetero, fallback=lambda: nx2hetero(get_g()))\n",
    "get_datasets = lambda: get_cached(\"datasets\", pickled_datasets, fallback=lambda: ghetero2datasets(get_ghetero()))\n",
    "\n",
    "ghetero = get_ghetero()\n",
    "datasets = get_datasets()\n",
    "data_train, data_val, data_test = datasets\n",
    "print(\"Finished loading data.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training mask for playlist nodes\n",
    "train_mask = torch.zeros(ghetero[\"playlist\"].x.shape[0], dtype=torch.bool)\n",
    "train_mask[torch.randperm(train_mask.shape[0])[:int(train_mask.shape[0]*0.8)]] = True\n",
    "\n",
    "ghetero[\"playlist\"].train_mask = train_mask\n",
    "\n",
    "ghetero[\"playlist\"].y = torch.LongTensor([1]*ghetero[\"playlist\"].x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch_geometric.nn.SAGEConv((-1, -1), hidden_channels, normalize=True)\n",
    "        self.conv2 = torch_geometric.nn.SAGEConv((-1, -1), hidden_channels, normalize=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "class LinkPredictor(torch.nn.Module):\n",
    "    def forward(self, x_playlist, x_track, playlist_track_edge):\n",
    "        playlist_embedding = x_playlist[playlist_track_edge[0]]\n",
    "        track_embedding = x_track[playlist_track_edge[1]]\n",
    "\n",
    "        # Apply dot-product to get a prediction per supervision edge:\n",
    "        return (playlist_embedding * track_embedding).sum(dim=-1)\n",
    "\n",
    "class HeteroModel(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, node_features, metadata):\n",
    "        super().__init__()\n",
    "        # Since the dataset does not come with rich features, we also learn two\n",
    "        # embedding matrices for users and movies:\n",
    "        \n",
    "        self.node_lin = {\n",
    "            k: torch.nn.Linear(v.shape[1], hidden_channels) for k, v in node_features.items()\n",
    "        }\n",
    "\n",
    "        for _, v in self.node_lin.items():\n",
    "            torch.nn.init.xavier_uniform_(v.weight)\n",
    "        \n",
    "        # Instantiate homogeneous GNN:\n",
    "        self.gnn = GNN(hidden_channels)\n",
    "        # Convert GNN model into a heterogeneous variant:\n",
    "        self.gnn = torch_geometric.nn.to_hetero(self.gnn, metadata=metadata)\n",
    "\n",
    "        self.classifier = LinkPredictor()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x_dict = {\n",
    "            k: self.node_lin[k](v) for k, v in data.x_dict.items()\n",
    "        }\n",
    "        \n",
    "        x_dict = self.gnn(x_dict, data.edge_index_dict)\n",
    "        pred = self.classifier(\n",
    "            x_dict[\"playlist\"],\n",
    "            x_dict[\"track\"],\n",
    "            data[\"track\", \"contains\", \"playlist\"].edge_index,\n",
    "        )\n",
    "        return pred\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for _, v in self.node_lin.items():\n",
    "            torch.nn.init.xavier_uniform_(v.weight)\n",
    "        self.gnn.reset_parameters()\n",
    "\n",
    "model = HeteroModel(64, ghetero.x_dict, ghetero.metadata())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EdgeStorage' object has no attribute 'edge_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/jupyter-server/venv/lib/python3.10/site-packages/torch_geometric/data/storage.py:62\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 62\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m[key]\n\u001b[1;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/jupyter-server/venv/lib/python3.10/site-packages/torch_geometric/data/storage.py:85\u001b[0m, in \u001b[0;36mBaseStorage.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m---> 85\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mapping[key]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'edge_index'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m edge_label_index \u001b[39m=\u001b[39m data_train[\u001b[39m\"\u001b[39m\u001b[39mtrack\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontains\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mplaylist\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39medge_label_index\n\u001b[1;32m      2\u001b[0m edge_label \u001b[39m=\u001b[39m data_train[\u001b[39m\"\u001b[39m\u001b[39mtrack\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontains\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mplaylist\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39medge_label\n\u001b[0;32m----> 3\u001b[0m train_loader \u001b[39m=\u001b[39m torch_geometric\u001b[39m.\u001b[39;49mloader\u001b[39m.\u001b[39;49mLinkNeighborLoader(\n\u001b[1;32m      4\u001b[0m     data\u001b[39m=\u001b[39;49mdata_train,\n\u001b[1;32m      5\u001b[0m     num_neighbors\u001b[39m=\u001b[39;49m[\u001b[39m20\u001b[39;49m, \u001b[39m10\u001b[39;49m],\n\u001b[1;32m      6\u001b[0m     neg_sampling_ratio\u001b[39m=\u001b[39;49m\u001b[39m2.0\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m     edge_label_index\u001b[39m=\u001b[39;49m((\u001b[39m\"\u001b[39;49m\u001b[39mtrack\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontains\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mplaylist\u001b[39;49m\u001b[39m\"\u001b[39;49m), edge_label_index),\n\u001b[1;32m      8\u001b[0m     edge_label\u001b[39m=\u001b[39;49medge_label,\n\u001b[1;32m      9\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m     shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(train_loader))\n",
      "File \u001b[0;32m~/jupyter-server/venv/lib/python3.10/site-packages/torch_geometric/loader/link_neighbor_loader.py:206\u001b[0m, in \u001b[0;36mLinkNeighborLoader.__init__\u001b[0;34m(self, data, num_neighbors, edge_label_index, edge_label, edge_label_time, replace, directed, disjoint, temporal_strategy, neg_sampling, neg_sampling_ratio, time_attr, transform, is_sorted, filter_per_worker, neighbor_sampler, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    199\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived conflicting \u001b[39m\u001b[39m'\u001b[39m\u001b[39medge_label_time\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtime_attr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    200\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39marguments: \u001b[39m\u001b[39m'\u001b[39m\u001b[39medge_label_time\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    201\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39mset\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39mif\u001b[39;00m\u001b[39m \u001b[39medge_label_time\u001b[39m \u001b[39m\u001b[39mis\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mnot\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mNone\u001b[39;00m\u001b[39m \u001b[39m\u001b[39melse\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39mnot set\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    202\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwhile \u001b[39m\u001b[39m'\u001b[39m\u001b[39minput_time\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    203\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39mset\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39mif\u001b[39;00m\u001b[39m \u001b[39mtime_attr\u001b[39m \u001b[39m\u001b[39mis\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mnot\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mNone\u001b[39;00m\u001b[39m \u001b[39m\u001b[39melse\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39mnot set\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    205\u001b[0m \u001b[39mif\u001b[39;00m neighbor_sampler \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m     neighbor_sampler \u001b[39m=\u001b[39m NeighborSampler(\n\u001b[1;32m    207\u001b[0m         data,\n\u001b[1;32m    208\u001b[0m         num_neighbors\u001b[39m=\u001b[39;49mnum_neighbors,\n\u001b[1;32m    209\u001b[0m         replace\u001b[39m=\u001b[39;49mreplace,\n\u001b[1;32m    210\u001b[0m         directed\u001b[39m=\u001b[39;49mdirected,\n\u001b[1;32m    211\u001b[0m         disjoint\u001b[39m=\u001b[39;49mdisjoint,\n\u001b[1;32m    212\u001b[0m         temporal_strategy\u001b[39m=\u001b[39;49mtemporal_strategy,\n\u001b[1;32m    213\u001b[0m         input_type\u001b[39m=\u001b[39;49medge_type,\n\u001b[1;32m    214\u001b[0m         time_attr\u001b[39m=\u001b[39;49mtime_attr,\n\u001b[1;32m    215\u001b[0m         is_sorted\u001b[39m=\u001b[39;49mis_sorted,\n\u001b[1;32m    216\u001b[0m         share_memory\u001b[39m=\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39mnum_workers\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m0\u001b[39;49m) \u001b[39m>\u001b[39;49m \u001b[39m0\u001b[39;49m,\n\u001b[1;32m    217\u001b[0m     )\n\u001b[1;32m    219\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[1;32m    220\u001b[0m     data\u001b[39m=\u001b[39mdata,\n\u001b[1;32m    221\u001b[0m     link_sampler\u001b[39m=\u001b[39mneighbor_sampler,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    230\u001b[0m )\n",
      "File \u001b[0;32m~/jupyter-server/venv/lib/python3.10/site-packages/torch_geometric/sampler/neighbor_sampler.py:95\u001b[0m, in \u001b[0;36mNeighborSampler.__init__\u001b[0;34m(self, data, num_neighbors, replace, directed, disjoint, temporal_strategy, input_type, time_attr, is_sorted, share_memory)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_type \u001b[39m=\u001b[39m input_type\n\u001b[1;32m     94\u001b[0m \u001b[39m# Obtain CSC representations for in-memory sampling:\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m out \u001b[39m=\u001b[39m to_hetero_csc(data, device\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m, share_memory\u001b[39m=\u001b[39;49mshare_memory,\n\u001b[1;32m     96\u001b[0m                     is_sorted\u001b[39m=\u001b[39;49mis_sorted,\n\u001b[1;32m     97\u001b[0m                     node_time_dict\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_time)\n\u001b[1;32m     98\u001b[0m colptr_dict, row_dict, perm_dict \u001b[39m=\u001b[39m out\n\u001b[1;32m    100\u001b[0m \u001b[39m# Conversions to/from C++ string type:\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[39m# Since C++ cannot take dictionaries with tuples as key as input,\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[39m# edge type triplets need to be converted into single strings. This\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39m# is done by maintaining the following mappings:\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyter-server/venv/lib/python3.10/site-packages/torch_geometric/sampler/utils.py:111\u001b[0m, in \u001b[0;36mto_hetero_csc\u001b[0;34m(data, device, share_memory, is_sorted, node_time_dict)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39mfor\u001b[39;00m edge_type, store \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39medge_items():\n\u001b[1;32m    110\u001b[0m     src_node_time \u001b[39m=\u001b[39m (node_time_dict \u001b[39mor\u001b[39;00m {})\u001b[39m.\u001b[39mget(edge_type[\u001b[39m0\u001b[39m], \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 111\u001b[0m     out \u001b[39m=\u001b[39m to_csc(store, device, share_memory, is_sorted, src_node_time)\n\u001b[1;32m    112\u001b[0m     colptr_dict[edge_type], row_dict[edge_type], perm_dict[edge_type] \u001b[39m=\u001b[39m out\n\u001b[1;32m    114\u001b[0m \u001b[39mreturn\u001b[39;00m colptr_dict, row_dict, perm_dict\n",
      "File \u001b[0;32m~/jupyter-server/venv/lib/python3.10/site-packages/torch_geometric/sampler/utils.py:67\u001b[0m, in \u001b[0;36mto_csc\u001b[0;34m(data, device, share_memory, is_sorted, src_node_time)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     colptr, row, _ \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39madj_t\u001b[39m.\u001b[39mcsr()\n\u001b[0;32m---> 67\u001b[0m \u001b[39melif\u001b[39;00m data\u001b[39m.\u001b[39;49medge_index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m     row, col \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39medge_index\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_sorted:\n",
      "File \u001b[0;32m~/jupyter-server/venv/lib/python3.10/site-packages/torch_geometric/data/storage.py:64\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[key]\n\u001b[1;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EdgeStorage' object has no attribute 'edge_index'"
     ]
    }
   ],
   "source": [
    "edge_label_index = data_train[\"track\", \"contains\", \"playlist\"].edge_label_index\n",
    "edge_label = data_train[\"track\", \"contains\", \"playlist\"].edge_label\n",
    "train_loader = torch_geometric.loader.LinkNeighborLoader(\n",
    "    data=data_train,\n",
    "    num_neighbors=[20, 10],\n",
    "    neg_sampling_ratio=2.0,\n",
    "    edge_label_index=((\"track\", \"contains\", \"playlist\"), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_examples = total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        # batch = batch.to('cuda:0')\n",
    "        batch_size = 100\n",
    "        out = model(batch)\n",
    "        loss = torch.nn.functional.cross_entropy(\n",
    "            out, batch[\"track\", \"contains\", \"playlist\"].edge_label\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_examples += batch_size\n",
    "        print(f'Loss: {loss:.4f}')\n",
    "        total_loss += float(loss) * batch_size\n",
    "\n",
    "    return total_loss / total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train()\n",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m      4\u001b[0m total_examples \u001b[39m=\u001b[39m total_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m      6\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m      7\u001b[0m     \u001b[39m# batch = batch.to('cuda:0')\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
