{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will train a GNN to perform link prediction on a heterogenous graph from the Spotify Million Playlists dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/yon/jupyter-server/venv/lib64/python3.10/site-packages (1.24.2)\n",
      "Requirement already satisfied: iprogress in /home/yon/jupyter-server/venv/lib/python3.10/site-packages (0.4)\n",
      "Requirement already satisfied: tqdm in /home/yon/jupyter-server/venv/lib/python3.10/site-packages (4.64.1)\n",
      "Requirement already satisfied: networkx in /home/yon/jupyter-server/venv/lib/python3.10/site-packages (3.0)\n",
      "Requirement already satisfied: torch_geometric in /home/yon/jupyter-server/venv/lib/python3.10/site-packages (2.2.0)\n",
      "Requirement already satisfied: six in /home/yon/jupyter-server/venv/lib/python3.10/site-packages (from iprogress) (1.16.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/yon/jupyter-server/venv/lib64/python3.10/site-packages (from torch_geometric) (5.9.4)\n",
      "Requirement already satisfied: scipy in /home/yon/jupyter-server/venv/lib64/python3.10/site-packages (from torch_geometric) (1.10.1)\n",
      "Requirement already satisfied: pyparsing in /home/yon/jupyter-server/venv/lib/python3.10/site-packages (from torch_geometric) (3.0.9)\n",
      "Requirement already satisfied: requests in /home/yon/jupyter-server/venv/lib/python3.10/site-packages (from torch_geometric) (2.28.2)\n",
      "Requirement already satisfied: scikit-learn in /home/yon/jupyter-server/venv/lib64/python3.10/site-packages (from torch_geometric) (1.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/yon/jupyter-server/venv/lib/python3.10/site-packages (from torch_geometric) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/yon/jupyter-server/venv/lib64/python3.10/site-packages (from jinja2->torch_geometric) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/yon/jupyter-server/venv/lib64/python3.10/site-packages (from requests->torch_geometric) (3.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/yon/jupyter-server/venv/lib/python3.10/site-packages (from requests->torch_geometric) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/yon/jupyter-server/venv/lib/python3.10/site-packages (from requests->torch_geometric) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/yon/jupyter-server/venv/lib/python3.10/site-packages (from requests->torch_geometric) (3.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/yon/jupyter-server/venv/lib/python3.10/site-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/yon/jupyter-server/venv/lib/python3.10/site-packages (from scikit-learn->torch_geometric) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy iprogress tqdm networkx torch_geometric\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary imports (delete later)\n",
    "from pprint import pprint\n",
    "import random\n",
    "import numpy as np\n",
    "# http://192.168.0.103:8888/?token=klobasa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "base = \"spotify_million_playlist_dataset\"\n",
    "pickles = base + \"/pickles\"\n",
    "\n",
    "# full dataset\n",
    "dataset_path = base + \"/data\"\n",
    "pickled_graph = pickles + \"/G.pkl\"\n",
    "pickled_datasets = pickles + \"/datasets.pkl\"\n",
    "pickled_ghetero = pickles + \"/ghetero.pkl\"\n",
    "\n",
    "# example dataset (override above)\n",
    "dataset_path = base + \"/example\"\n",
    "pickled_graph = pickles + \"/G_example.pkl\"\n",
    "pickled_datasets = pickles + \"/datasets_example.pkl\"\n",
    "pickled_ghetero = pickles + \"/ghetero_example.pkl\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(dataset_path=dataset_path):\n",
    "    \"\"\"Load a nx.Graph from disk.\"\"\"\n",
    "    filenames = os.listdir(dataset_path)\n",
    "    G = nx.DiGraph()\n",
    "    for i in tqdm(range(len(filenames)), unit=\"files\"):\n",
    "        with open(os.path.join(dataset_path, filenames[i])) as json_file:\n",
    "            playlists = json.load(json_file)[\"playlists\"]\n",
    "            for playlist in playlists:\n",
    "                playlist_name = f\"spotify:playlist:{playlist['pid']}\"\n",
    "                G.add_node(playlist_name, node_type=\"playlist\", num_followers=playlist[\"num_followers\"])\n",
    "                for track in playlist[\"tracks\"]:\n",
    "                    G.add_node(track[\"track_uri\"], node_type=\"track\", duration=track[\"duration_ms\"])\n",
    "                    G.add_node(track[\"album_uri\"], node_type=\"album\")\n",
    "                    G.add_node(track[\"artist_uri\"], node_type=\"artist\")\n",
    "\n",
    "                    G.add_edge(track[\"track_uri\"], playlist_name, edge_type=\"track-playlist\")\n",
    "                    G.add_edge(track[\"track_uri\"], track[\"album_uri\"], edge_type=\"track-album\")\n",
    "                    G.add_edge(track[\"track_uri\"], track[\"artist_uri\"], edge_type=\"track-artist\")\n",
    "    return G\n",
    "\n",
    "def nx2hetero(graph_getter):\n",
    "    G = graph_getter\n",
    "    \"\"\"Convert a nx.Graph into a torch_geometric.data.HeteroData object.\"\"\"\n",
    "    ids_by_type = {\n",
    "        \"playlist\": {},\n",
    "        \"track\": {},\n",
    "        \"artist\": {},\n",
    "        \"album\": {}\n",
    "    }\n",
    "    \n",
    "    def node_id(node_type, id):\n",
    "        d = ids_by_type[node_type]\n",
    "        if id not in d:\n",
    "            d[id] = len(d)\n",
    "        return d[id]\n",
    "\n",
    "    node_features_by_type = {\n",
    "        \"playlist\": [],\n",
    "        \"track\": [],\n",
    "        \"artist\": [],\n",
    "        \"album\": []\n",
    "    }\n",
    "    for node in G.nodes(data=True):\n",
    "        t = node[1][\"node_type\"]\n",
    "        node_id(t, node[0])\n",
    "        if t == \"playlist\":\n",
    "            node_features_by_type[\"playlist\"] += [node[1][\"num_followers\"]]\n",
    "        elif t == \"track\":\n",
    "            node_features_by_type[\"track\"] += [node[1][\"duration\"]]\n",
    "        elif t == \"artist\":\n",
    "            node_features_by_type[\"artist\"] += [1]\n",
    "        elif t == \"album\":\n",
    "            node_features_by_type[\"album\"] += [1]\n",
    "\n",
    "    edge_index_by_type = {\n",
    "        (\"track\", \"contains\", \"playlist\"): [],\n",
    "        (\"track\", \"includes\", \"album\"): [],\n",
    "        (\"track\", \"authors\", \"artist\"): []\n",
    "    }\n",
    "    for edge in G.edges(data=True):\n",
    "        if G[edge[0]][edge[1]][\"edge_type\"] == \"track-playlist\":\n",
    "            s_id = node_id(\"track\", edge[0])\n",
    "            d_id = node_id(\"playlist\", edge[1])\n",
    "            edge_index_by_type[(\"track\", \"contains\", \"playlist\")] += [(s_id, d_id)]\n",
    "        elif G[edge[0]][edge[1]][\"edge_type\"] == \"track-album\":\n",
    "            s_id = node_id(\"track\", edge[0])\n",
    "            d_id = node_id(\"album\", edge[1])\n",
    "            edge_index_by_type[(\"track\", \"includes\", \"album\")] += [(s_id, d_id)]\n",
    "        elif G[edge[0]][edge[1]][\"edge_type\"] == \"track-artist\":\n",
    "            s_id = node_id(\"track\", edge[0])\n",
    "            d_id = node_id(\"artist\", edge[1])\n",
    "            edge_index_by_type[(\"track\", \"authors\", \"artist\")] += [(s_id, d_id)]\n",
    "\n",
    "    # construct HeteroData\n",
    "    hetero = torch_geometric.data.HeteroData()\n",
    "\n",
    "    # add initial node features\n",
    "    hetero[\"playlist\"].x = torch.FloatTensor(node_features_by_type[\"playlist\"]).reshape(-1,1)\n",
    "    hetero[\"track\"].x = torch.FloatTensor(node_features_by_type[\"track\"]).reshape(-1,1)\n",
    "    hetero[\"artist\"].x = torch.FloatTensor(node_features_by_type[\"artist\"]).reshape(-1,1)\n",
    "    hetero[\"album\"].x = torch.FloatTensor(node_features_by_type[\"album\"]).reshape(-1,1)\n",
    "\n",
    "    # add edge indices\n",
    "    hetero[\"track\", \"contains\", \"playlist\"].edge_index = torch.tensor(edge_index_by_type[(\"track\", \"contains\", \"playlist\")]).t()\n",
    "    hetero[\"track\", \"includes\", \"album\"].edge_index = torch.tensor(edge_index_by_type[(\"track\", \"includes\", \"album\")]).t()\n",
    "    hetero[\"track\", \"authors\", \"artist\"].edge_index = torch.tensor(edge_index_by_type[(\"track\", \"authors\", \"artist\")]).t()\n",
    "\n",
    "    # post-processing\n",
    "    hetero = torch_geometric.transforms.ToUndirected()(hetero)\n",
    "    hetero = torch_geometric.transforms.RemoveIsolatedNodes()(hetero)\n",
    "    assert hetero.validate()\n",
    "    return hetero\n",
    "\n",
    "def get_cached(var, pickled_filename, fallback, ignore_cache=False):\n",
    "    \"\"\"Get a variable from cache.\n",
    "    \n",
    "    First, check global memory (variable `var`).\n",
    "    If not found, check pickle (file `pickled_filename`).\n",
    "    If not found, generate anew (use `fallback` function).\n",
    "    \"\"\"\n",
    "    if not ignore_cache and var in globals():\n",
    "        print(f\"Using {var} from global memory ...\")\n",
    "        return globals()[var]\n",
    "    elif not ignore_cache and os.path.exists(pickled_filename):\n",
    "        print(f\"Loading {var} from pickle ...\")\n",
    "        return pickle.load(open(pickled_filename, \"rb\"))\n",
    "    else:\n",
    "        print(f\"Pickled {var} not found, generating anew ...\")\n",
    "        obj = fallback()\n",
    "        pickle.dump(obj, open(pickled_filename, \"wb\"))\n",
    "        print(f\"{var} generated, pickle saved to {pickled_filename}\")\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm ../spotify_million_playlist_dataset/pickles/datasets_example.pkl\n",
    "# !rm ../spotify_million_playlist_dataset/pickles/G_example.pkl\n",
    "# !rm ../spotify_million_playlist_dataset/pickles/ghetero_example.pkl\n",
    "# !ls ../spotify_million_playlist_dataset/pickles/\n",
    "# del G\n",
    "# del ghetero\n",
    "# del datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ghetero2datasets(ghetero):\n",
    "    \"\"\"Split the dataset into train, validation and test sets.\"\"\"\n",
    "    transform = torch_geometric.transforms.RandomLinkSplit(\n",
    "        num_val=0.1,\n",
    "        num_test=0.1,\n",
    "        disjoint_train_ratio=0.3,\n",
    "        neg_sampling_ratio=2.0,\n",
    "        add_negative_train_samples=False,\n",
    "        edge_types=(\"track\", \"contains\", \"playlist\"),\n",
    "        rev_edge_types=(\"playlist\", \"rev_contains\", \"track\"),\n",
    "    )\n",
    "\n",
    "    return transform(ghetero)  # 3-tuple: data_train, data_val, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ghetero from global memory ...\n",
      "Using datasets from global memory ...\n",
      "Finished loading data.\n"
     ]
    }
   ],
   "source": [
    "get_g = lambda: get_cached(\"G\", pickled_graph, fallback=load_graph)\n",
    "get_ghetero = lambda: get_cached(\"ghetero\", pickled_ghetero, fallback=lambda: nx2hetero(get_g()))\n",
    "get_datasets = lambda: get_cached(\"datasets\", pickled_datasets, fallback=lambda: ghetero2datasets(get_ghetero()))\n",
    "\n",
    "ghetero = get_ghetero()\n",
    "datasets = get_datasets()\n",
    "data_train, data_val, data_test = datasets\n",
    "print(\"Finished loading data.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training mask for playlist nodes\n",
    "train_mask = torch.zeros(ghetero[\"playlist\"].x.shape[0], dtype=torch.bool)\n",
    "train_mask[torch.randperm(train_mask.shape[0])[:int(train_mask.shape[0]*0.8)]] = True\n",
    "\n",
    "ghetero[\"playlist\"].train_mask = train_mask\n",
    "\n",
    "ghetero[\"playlist\"].y = torch.LongTensor([1]*ghetero[\"playlist\"].x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch_geometric.nn.SAGEConv((-1, -1), hidden_channels, normalize=True)\n",
    "        self.conv2 = torch_geometric.nn.SAGEConv((-1, -1), hidden_channels, normalize=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "class LinkPredictor(torch.nn.Module):\n",
    "    def forward(self, x_track, x_playlist, track_playlist_edge):\n",
    "        track_embedding = x_track[track_playlist_edge[0]]\n",
    "        playlist_embedding = x_playlist[track_playlist_edge[1]]\n",
    "\n",
    "        # Apply dot-product to get a prediction per supervision edge:\n",
    "        return (playlist_embedding * track_embedding).sum(dim=-1)\n",
    "\n",
    "class HeteroModel(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, node_features, metadata):\n",
    "        super().__init__()\n",
    "        # Since the dataset does not come with rich features, we also learn two\n",
    "        # embedding matrices for users and movies:\n",
    "        \n",
    "        self.node_lin = {\n",
    "            k: torch.nn.Linear(v.shape[1], hidden_channels) for k, v in node_features.items()\n",
    "        }\n",
    "\n",
    "        for _, v in self.node_lin.items():\n",
    "            torch.nn.init.xavier_uniform_(v.weight)\n",
    "        \n",
    "        # Instantiate homogeneous GNN:\n",
    "        self.gnn = GNN(hidden_channels)\n",
    "        # Convert GNN model into a heterogeneous variant:\n",
    "        self.gnn = torch_geometric.nn.to_hetero(self.gnn, metadata=metadata)\n",
    "\n",
    "        self.classifier = LinkPredictor()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x_dict = {\n",
    "            k: self.node_lin[k](v) for k, v in data.x_dict.items()\n",
    "        }\n",
    "        \n",
    "        x_dict = self.gnn(x_dict, data.edge_index_dict)\n",
    "        pred = self.classifier(\n",
    "            x_dict[\"track\"],\n",
    "            x_dict[\"playlist\"],\n",
    "            data[\"track\", \"contains\", \"playlist\"].edge_label_index,\n",
    "        )\n",
    "        return pred\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for _, v in self.node_lin.items():\n",
    "            torch.nn.init.xavier_uniform_(v.weight)\n",
    "        self.gnn.reset_parameters()\n",
    "\n",
    "model = HeteroModel(64, ghetero.x_dict, ghetero.metadata())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_label_index = data_train[\"track\", \"contains\", \"playlist\"].edge_label_index\n",
    "edge_label = data_train[\"track\", \"contains\", \"playlist\"].edge_label\n",
    "train_loader = torch_geometric.loader.LinkNeighborLoader(\n",
    "    data=data_train,\n",
    "    num_neighbors=[20, 10],\n",
    "    neg_sampling_ratio=2.0,\n",
    "    edge_label_index=((\"track\", \"contains\", \"playlist\"), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_examples = total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch.to('cuda:0')\n",
    "        batch_size = 100\n",
    "        out = model(batch)\n",
    "        loss = torch.nn.functional.cross_entropy(\n",
    "            out, batch[\"track\", \"contains\", \"playlist\"].edge_label\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_examples += batch_size\n",
    "        print(f'Loss: {loss:.4f}')\n",
    "        total_loss += float(loss) * batch_size\n",
    "\n",
    "    return total_loss / total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 761.8414\n",
      "Loss: 759.3619\n",
      "Loss: 762.1827\n",
      "Loss: 761.2241\n",
      "Loss: 761.4955\n",
      "Loss: 761.5721\n",
      "Loss: 761.2287\n",
      "Loss: 760.9959\n",
      "Loss: 760.6590\n",
      "Loss: 760.1034\n",
      "Loss: 760.3151\n",
      "Loss: 759.1165\n",
      "Loss: 760.4759\n",
      "Loss: 759.1173\n",
      "Loss: 760.6943\n",
      "Loss: 759.2424\n",
      "Loss: 759.7942\n",
      "Loss: 760.5875\n",
      "Loss: 760.9835\n",
      "Loss: 761.6185\n",
      "Loss: 759.3360\n",
      "Loss: 761.9995\n",
      "Loss: 761.4413\n",
      "Loss: 760.8193\n",
      "Loss: 760.9785\n",
      "Loss: 760.3000\n",
      "Loss: 761.7486\n",
      "Loss: 759.7693\n",
      "Loss: 759.5469\n",
      "Loss: 759.5927\n",
      "Loss: 760.6370\n",
      "Loss: 761.2018\n",
      "Loss: 758.3416\n",
      "Loss: 760.1608\n",
      "Loss: 759.6035\n",
      "Loss: 760.1858\n",
      "Loss: 760.1282\n",
      "Loss: 758.9980\n",
      "Loss: 760.2808\n",
      "Loss: 758.8284\n",
      "Loss: 759.9775\n",
      "Loss: 758.7100\n",
      "Loss: 760.3772\n",
      "Loss: 758.8898\n",
      "Loss: 758.7626\n",
      "Loss: 761.6842\n",
      "Loss: 760.8819\n",
      "Loss: 759.4440\n",
      "Loss: 760.4081\n",
      "Loss: 759.8478\n",
      "Loss: 758.4083\n",
      "Loss: 761.3316\n",
      "Loss: 760.0054\n",
      "Loss: 760.4619\n",
      "Loss: 760.2502\n",
      "Loss: 759.9586\n",
      "Loss: 758.6992\n",
      "Loss: 758.6745\n",
      "Loss: 756.6503\n",
      "Loss: 759.1357\n",
      "Loss: 758.2160\n",
      "Loss: 762.2259\n",
      "Loss: 758.0843\n",
      "Loss: 759.9832\n",
      "Loss: 759.8146\n",
      "Loss: 762.2816\n",
      "Loss: 757.4725\n",
      "Loss: 760.5807\n",
      "Loss: 760.2988\n",
      "Loss: 760.7910\n",
      "Loss: 761.6173\n",
      "Loss: 759.2943\n",
      "Loss: 760.0740\n",
      "Loss: 760.5674\n",
      "Loss: 761.2035\n",
      "Loss: 759.0050\n",
      "Loss: 760.3903\n",
      "Loss: 759.8593\n",
      "Loss: 760.4442\n",
      "Loss: 759.9719\n",
      "Loss: 759.4535\n",
      "Loss: 762.2039\n",
      "Loss: 759.0071\n",
      "Loss: 762.4654\n",
      "Loss: 758.5460\n",
      "Loss: 762.5823\n",
      "Loss: 761.1385\n",
      "Loss: 760.9700\n",
      "Loss: 760.7914\n",
      "Loss: 759.8802\n",
      "Loss: 759.0182\n",
      "Loss: 759.4733\n",
      "Loss: 760.9554\n",
      "Loss: 760.7877\n",
      "Loss: 761.4502\n",
      "Loss: 761.3358\n",
      "Loss: 758.7146\n",
      "Loss: 760.9078\n",
      "Loss: 760.5024\n",
      "Loss: 758.7770\n",
      "Loss: 758.9397\n",
      "Loss: 761.5849\n",
      "Loss: 759.0952\n",
      "Loss: 759.5280\n",
      "Loss: 758.8719\n",
      "Loss: 759.7069\n",
      "Loss: 757.7145\n",
      "Loss: 758.8640\n",
      "Loss: 762.9927\n",
      "Loss: 761.9597\n",
      "Loss: 760.7225\n",
      "Loss: 760.3923\n",
      "Loss: 759.3594\n",
      "Loss: 761.0168\n",
      "Loss: 763.4586\n",
      "Loss: 759.5563\n",
      "Loss: 758.4349\n",
      "Loss: 761.6832\n",
      "Loss: 760.0930\n",
      "Loss: 760.8672\n",
      "Loss: 760.7302\n",
      "Loss: 759.1378\n",
      "Loss: 760.2988\n",
      "Loss: 761.9581\n",
      "Loss: 231.2892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "755.9876741943359"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fdd1bf0cdef9f431ef204eb65428406a6292ed13583a3a7833f3ab005ff2b93a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
